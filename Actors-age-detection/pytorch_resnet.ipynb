{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from __future__ import print_function, division\nimport numpy as np\nimport pandas as pd\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.optim import lr_scheduler\nfrom torch.utils.data import DataLoader, Dataset\nfrom torchvision import transforms, models\nimport torch.nn.functional as F\nfrom tqdm.notebook import tqdm\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nimport time\nimport os","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"TRAIN_IMG_PATH = \"../input/actorsdataset/train/Train/\"\nTEST_IMG_PATH = \"../input/actorsdataset/test/Test/\"\nLABELS_CSV_PATH = \"../input/actorsdataset/train.csv\"\nSAMPLE_SUB_PATH = \"../input/actorsdataset/test.csv\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Creating dict for one hot encoding \nagedict = {'YOUNG':0, 'MIDDLE':1, 'OLD':2}\nrevdict = {0:'YOUNG', 1:'MIDDLE', 2:'OLD'}","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(LABELS_CSV_PATH)\ndf['Class'] = df['Class'].map(agedict)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 90-10 split for train, test\ncut = int(len(df)*0.9)\ntrain, test = df[:cut], df[cut:].reset_index(drop=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class actorsDataset(Dataset):\n    \n    def __init__(self, img_dir, labels, transform=None):\n        self.labels = labels\n        self.dir = img_dir\n        self.transform = transform\n        \n    def __len__(self):\n        return(len(self.labels))\n    \n    def __getitem__(self, i):\n        img = os.path.join(self.dir, self.labels.ID[i])\n        image = Image.open(img)\n        label = self.labels['Class'][i]\n        \n        if self.transform:\n            image = self.transform(image)\n        \n        return [image, label]\n        ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_transform = transforms.Compose([\n    transforms.RandomResizedCrop(128),\n    transforms.ToTensor()\n])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = actorsDataset(TRAIN_IMG_PATH, train, data_transform)\ntest_df = actorsDataset(TRAIN_IMG_PATH, test, data_transform)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"datasets = {'train':train_df, 'val':test_df}","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### DataLoader\n\n**While training a model, we typically want to pass samples in “minibatches”, reshuffle the data at every epoch to reduce model overfitting, and use Python’s multiprocessing to speed up data retrieval.**\n\nDataLoader is an iterable that abstracts this complexity for us in an easy API.","metadata":{}},{"cell_type":"code","source":"trainloader = DataLoader(train_df, batch_size=32, shuffle=True)\ntestloader = DataLoader(test_df, batch_size=32, shuffle=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataloader = {'train':trainloader, 'val':testloader}","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n    since = time.time()\n    \n    # A state_dict() is simply a python ordered dictionary object that maps each parameter to its parameter tensor (torch.Tensor object). \n    # The keys of this ordered dictionary are the names of the parameters, which can be used to access the respective parameter tensors.\n    best_model = model.state_dict()\n    best_accu = 0.0\n    \n    for epoch in tqdm(range(num_epochs)):\n        \n        print('Epoch {}/{}'.format(epoch, num_epochs))\n        print('-*-'*10)\n        \n        since_epoch = time.time()\n        for phase in ['train','val']:\n\n                \n            run_loss = 0.0\n            corr = 0\n            \n            for data in tqdm(dataloader[phase]):\n                inputs, labels = data\n                \n                inputs = inputs.to(device)\n                labels = labels.to(device)\n                \n                # Sets the gradients of all optimized torch.Tensors to zero.\n                optimizer.zero_grad()\n                \n                # Context-manager that sets gradient calculation to on or off\n                with torch.set_grad_enabled(phase=='train'):\n                    outputs = model(inputs)\n                    _,preds = torch.max(outputs,1)\n                    loss = criterion(outputs, labels)\n                    \n                    if phase=='train':\n                        loss.backward()\n                        optimizer.step()\n                        \n                run_loss += loss.item() * inputs.size(0)\n                corr += torch.sum(preds==labels.data)\n            \n            if phase=='train':\n                # If not called the learning rate won’t be changed \n                # stays at the initial value.\n                scheduler.step()\n                model.train(True)\n            else:\n                model.train(False)\n                \n            epoch_loss = run_loss / len(datasets[phase])\n            epoch_accu = corr.double() / len(datasets[phase])\n            \n            time_epoch = time.time() - since_epoch\n            print('{} Loss: {:.4f} Acc: {:.4f} in {:.0f}m {:.0f}s'.format(phase, epoch_loss, epoch_accu, time_epoch // 60, time_epoch % 60))\n\n            \n            if phase=='val' and epoch_accu > best_accu:\n                best_accu = epoch_accu\n                best_model = model.state_dict()\n                \n        print()\n                \n    time_elaps = time.time() - since\n    print('Training complete in {:.0f}m {:.0f}s'.format(time_elaps//60, time_elaps%60))\n    print('Best Val Acc: {:4f}'.format(best_accu))\n    \n    return model\n                        ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### optimizer.zero_grad()\n\n**we need to set the gradients to zero before starting to do backpropragation because PyTorch accumulates the gradients on subsequent backward passes**\n\n##### Deafult Behavior is Useful for RNNs\n\n**Because of this, when you start your training loop, ideally you should zero out the gradients so that you do the parameter update correctly. Else the gradient would point in some other direction than the intended direction towards the minimum**","metadata":{}},{"cell_type":"markdown","source":"### loss.backward() || optimizer.step()\n\nWhen you call loss.backward(), all it does is compute gradient of loss w.r.t all the parameters in loss that have requires_grad = True and store them in parameter.grad attribute for every parameter.\n\noptimizer.step() updates all the parameters based on parameter.grad","metadata":{}},{"cell_type":"code","source":"class actorCNN(nn.Module):\n    \n    def __init__(self):\n        \n        super(actorCNN, self).__init__()\n        \n        self.model = models.resnet18(pretrained=True)\n        \n        for params in self.model.parameters():\n            params.requires_grad=False\n            \n        self.model.fc = nn.Linear(512, 512)\n        self.l = nn.ReLU(inplace=True)\n        self.fc2 = nn.Linear(512, 3)\n        \n        self.classifier = nn.Sequential(self.model, self.l, self.fc2)\n        \n    def forward(self, x):\n        return self.classifier(x)\n    \n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_epochs = 25\nnum_classes = 3\nbatch_size = 128\nlearning_rate = 0.002\ndevice = torch.device('cuda:0' if torch.cuda.is_available() else \"cpu\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = actorCNN().to(device)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"criterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)\nexp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_ft = train_model(model, criterion, optimizer, exp_lr_scheduler)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_df = pd.read_csv(SAMPLE_SUB_PATH)\n\noutput_df = pd.DataFrame(index=submission_df.index, columns = submission_df.keys())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"output_df['ID'] = submission_df['ID']\noutput_df['Class'] = [0]*len(submission_df)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_df = actorsDataset(TEST_IMG_PATH, output_df, data_transform)\nsub_loader = DataLoader(submission_df, batch_size=1, shuffle=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def test_sub(model):\n    \n    prediction = []\n    model.train(False)\n    \n    for data in sub_loader:\n        inputs, labels = data\n        \n        inputs = inputs.to(device)\n        labels = labels.to(device)\n        \n        outputs = model(inputs)\n        _, pred = torch.max(outputs.data, 1)\n        prediction.append(int(pred))\n        \n    return prediction","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"output_df['Class'] = test_sub(model_ft)\n\noutput_df['Class'] = output_df['Class'].map(revdict)\noutput_df.to_csv('submission.csv', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}